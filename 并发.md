# 什么是并发、并行、串行？并发带来的问题以及解决方式
- 看视频前的理解：
    首先需要讲清楚线程和进程的概念。操作系统上运行了很多程序，比如：JVM/MySQL，像这样的程序就叫做“进程”。进程是操作系统最小的调度单位，进程共享内存、磁盘等资源，进程一旦启动操作系统就会为它分配相应的资源。线程是CPU最小的执行单元，线程启动时，会为其分配栈内存、程序计数器。

    在一个运行的进程中，一个资源（数据）被多条线程同时访问，造成数据不安全地访问，这样就是叫并发。同时多条线程不存在竞争同一资源，这叫并行，还有就是在操作系统中运行的不同软件，也叫进程并行。在同一个进程中，多个任务，先要执行任务A，然后再执行任务B，这就叫串行。

    线程并发会导致某些共享数据出现错误的状态，导致线程不安全。解决并发问题的方式是加锁，我们可以让某个竞争资源在某一个时刻只能让一条线程访问，其他要访问的线程先等待或挂起，直到持有锁线程处理完成释放锁后，唤醒等待线程再去竞争锁，拿到锁后继续处理任务。
- 看视频后的理解： 
    假如一个下单接口在一秒内支持10个请求，这样系统无法同时满足超过10个用户的下单需求。为了解决这个问题，我们可以增加处理下单的线程数量，比如增加3条线程，那么1秒内就可以处理30个请求，这样就可以满足更多用户的下单请求。

    多条线程在同一时刻执行相同的代码逻辑，就叫并发，比如CMS垃圾收集器在标记垃圾对象时，会开启多条线程去标记，这样可以提高收集器的标记效率。

    并发虽然可以提高处理效率，但同时也会带来一些问题，并发带来了原子性、可见性、顺序性问题。

    原子性问题就是有些命令在CPU层面会拆分成多条指令，比如i++，会拆分成从主存获取i的值，i加1和将i写回主存这样3条指令。在线程1从主存中获取i后，其他线程已经执行i加1操作，这样i的值就和线程1拿到的i值不一致，线程1将i加1后写回主存后就会覆盖其他线程的执行结果。

    可见性就是同一竞争资源的状态在不同线程中状态不一致，因为不同线程会将资源状态从主内存放在自己的工作内存中缓存，如果在放在工作内存中后，其他线程修改了这个状态，那么这个线程中的状态不是最新的，就导致可见性问题。

    顺序性问题就是在编译器、解释器、CPU层面为了提高程序执行性能，在保证程序最终结果正确性的前提下，会将程序指令的执行顺序不按照程序指定顺序执行。比如：int a=1; int b=1; 在执行时，第二句指令可能会先执行，这就导致其他依赖b的值的程序出问题。
        
    为了解决以上并发问题，提出了相应的解决方案。使用synchronized关键字来锁定要保证原子操作的代码，在synchronized锁定区域，只有一条线程能执行，解锁前需要把修改的状态写回主存，在加锁前需要将状态重新从主存中获取，这样解决了可见性和顺序性问题。可见性和顺序行问题可以使用volatile关键字来修饰，它会保证修改后的状态立马写回到主内存，这样其他线程拿到的值是最新的，对于已经获取的值的线程，就重新去主存中获取最新的值。volatile同时也保证程序执行的顺序。
# JVM 锁原理是什么？
JVM锁使用的是对象锁，实现原理是在对象头中有2bit用来标记锁的状态（无锁、偏向锁、轻量锁、重量级锁），还有用来存储偏向线程的线程ID。 在刚开始没有线程执行，此时对象是无锁状态。然后此时有一个线程A访问，这时对象会偏向这个线程，会记录相应的线程ID，锁状态变为偏向锁。如果在未释放锁时，又有另外一个线程B来访问，此时线程B会先自旋等待拿锁，此时锁状态为轻量级锁。如果线程B自旋后还是没拿到锁，对象锁就会升级为重量级锁--synchronized锁。

synchronized可以修饰方法，此时锁定的是整个方法，性能不高；还可以修饰某个代码块，可以锁定类和对象；锁定类，那么这个类的所有对象都会影响；锁定对象时，只有该对象才会有影响，其他的对象不影响。
# volatile解决的问题
volatile解决了并发的可见性和顺序性问题。多核CPU架构，在每核CPU有自己的3级缓存，操作数据都会先操作缓存，再写入主存中，这样就导致其他CPU核心的缓存数据可能和主存不一致。基于此，CPU设计团队设计了MESI协议和总线锁来解决这个问题。在使用数据时，会先查看自己缓存是否有数据，如果有就直接使用，如果没有就去其他核心和主存中去找。如果要修改数据，会先将修改后的数据写入自己的缓存，然后再通知其他核心有这个数据的缓存失效，写入主存中。由于通知其他核心和操作主存都需要将总线锁定，同时修改数据的CPU和其他CPU在读取和修改数据都需要等待响应的通知，这样有性能问题（阻塞），CPU设计团队设计出异步处理方式，在读取和修改数据的通知通过store buffer和buffer和invalidate queue去异步处理，修改数据的CPU在将数据写入store buffer后，并发送invalidate消息后，就可以继续做其他事情。在CPU空闲时，会将invalidae queue消息进行处理，告诉其他CPU缓存失效，将store buffer数据写入缓存行和同步主内存，这样就会导致内存重排序问题。使用内存屏障可以解决内存重排序问题，有以下3种：全屏障、写屏障、读屏障。全屏障是指在屏障前后的指令不能重排序，写屏障是指在写后所有store buffer的数据全部同步到缓存和内存中，读屏障是指读之前将所有的invalidate队列中的消息全部执行，同步各CPU种缓存行的数据。
# 什么是AQS、cas、lock锁的原理
AQS全称是AbstractQueueSynchronizer，抽象队列同步器。其内部设计了一个state和等待队列。如果有线程持有锁，state会从0设置为大于0 的数字。等待队列是一个双向链表，链表中的节点会存储节点状态和当前线程。在线程拿锁时，发现已有线程持有锁，则会先自旋拿锁，如果自旋后还是拿不到锁，则会将当前线程封装成等待队列中的节点，加入等待队列，进行挂起。CAS是compare and set，对比变量是否和预期值一样，一样就设置，不一样就设置不成功。lock的原理是判断state状态，如果状态为0，则可以拿锁。如果不为0则需要等待，甚至线程可能要挂起，等待被唤醒。线程挂起是使用LockSupport.park方法，使用unpark方法唤醒线程。
# ThreadLocal的流程 内存泄漏等问题
创建ThreadLocal对象可以是无参创建，也可以指定初始值。每条线程会有一个ThreadLocalMap对象，这个对象维护了一个Entry数组，每个Entry包含一个key和value，Entry对象是一个弱引用。key为ThreadLocal对象。在设置数据时，会判断当前线程是否有ThreadLocalMap对象，如果没有则会创建，然后将key和value封装成Entry，根据key的hashcode获取数组下标，放入数组。如果数组长度不够，则会对数组进行扩容（容量是原来的2倍）。如果存在hash冲突，则会将Entry对象放入下一个下表中（线性探测技术）。获取数据同样会判断ThreadLocalMap对象，如果没有则会创建，然后根据key获取数据。由于Entry对象的key对ThreadLocal对象是弱引用，所以在在线程中如果对ThreadLocal对象的强引用断掉后，此时，ThreadLcal对象则只有key对其的弱引用，在GC时，会将则ThreadLcal对象回收，这样ThreadLocalMap中会出现key为null的元素，如果存在很多线程都是这样的情况，那么就出现了内存泄漏问题。在使用完数据后，进行remove操作可防止这样的内存泄漏问题，同时jdk在添加和设置时，都会去扫描key为空的Entry元素并清除，如果在添加数据时，根据key计算的下标出现key为空，会直接使用该位置覆盖数据。
# HashMap存储数据的过程
HashMap的存储结构是数组，如果存在hash冲突时，会在相应的下标里存放链表，如果链表个数大于8并且数组长度小于64，则会将链表转成红黑树。在向HashMap中添加数据时，根据key的hashcode计算出下标，将key和value封装成数组元素Node，如果数组相应下标没有元素，则将Node放入；如果有元素，则将Node放入链表；如果链表数量大于8并且数组长度小于64，则将链表转成红黑树存储。如果在树的元素在减少过程中，元素个数少于6个，则将树转成聊表。如果数组长度大于了阈值（默认阈值为容量的75%），则会进行扩容（新容量是原容量的2倍）。为了减少hash冲突，采用扰动算法，尽量将key分散。、

HashMap是线程不安全的，如果要保证线程安全，则需要使用ConcurrentHashMap，增加、删除数据的方法都会采用自旋和互斥锁（lock或者synchronized）进行处理。
# synchronized和ReentrantLock有什么区别？在实际项目中，您如何选择使用它们？
synchronized和ReentrantLock都是可重入锁。synchronized是JVM通过monitor来实现的，而ReentrantLock是通过AQS来实现的。synchronized是非公平锁，ReentrantLock可实现公平锁和非公平锁。synchronized不支持中断请求，而ReentrantLock支持线程中断处理。synchronized不支持超时机制。
# 什么是死锁？如何预防和解决死锁？
死锁就是2条线程相互持有对方要获取的锁。线程1持有锁1，它需要去获取锁2，然后线程2持有锁2，要获取锁1，这样线程1和2就形成死锁。
    
使用重入锁可解决死锁问题
# 线程池的参数与实现原理
使用线程池的目的是管理启动的线程和达到线程的复用。那创建一个线程池需要哪些参数？有7个：
- 核心线程数：要创建的核心worker线程数
- 最大线程数：如果任务比较多，核心线程都在使用时，需要另外创建线程来处理新的任务，允许创建的worker线程的最大数量
- 线程存活时间：如果线程处于空闲状态，需要等多久回收
- 线程存活时间的单位
- 等待队列
- 创建线程的工厂
- 拒绝策略： 当等待队列已满时，还有新任务时，处理新任务的拒绝策略
## 实现原理
在向线程池中添加任务时，会判断当前worker线程数量，如果小于核心线程数，就会去启动一个work线程，然后执行任务中的run方法，任务中的run方法执行完后，会继续从阻塞队列里拿任务，如何队列没有任务，则线程会继续阻塞(queue.take)等待。如果worker线程数量大于核心线程数量，则会将任务加入阻塞队列。如果阻塞队列已满，则会创建新的worker线程。如果work线程数量大于最大线程数量，则执行拒绝策略。如果线程池允许worker线程回收，那么worker线程在空闲超过等待时间后，worker线程会停掉。
# 有哪几种线程池？说明不同线程池类型的使用场景及其优缺点？

# 阻塞队列有哪些？分别介绍一下

# 在并发编程中，CountDownLatch、CyclicBarrier和Semaphore有何异同？请举例说明它们各自的使用场景。
# 如何通过使用volatile关键字解决Java中的可见性问题？volatile与原子操作有什么关系？
volatile关键字可以修饰对象的成员变量，可保证成员变量的更新对所有线程可见。volatile只能解决可见性和指令重排问题，通过内存屏障解决变量的可见性问题。它不能解决原子性问题。
# ConcurrentHashMap在Java 8中相比之前的版本有哪些重要改进？如何将ConcurrentHashMap用作本地缓存，并处理过期时间或驱逐策略？
# ConcurrentHashMap 是线程安全的吗？在哪种情况下可能会出现数据一致性问题？您会如何防止这种情况发生？
# 在处理并发数据访问时，您是如何考虑选择乐观锁还是悲观锁的？为什么？
